{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed: https://www.youtube.com/watch?v=QpzMWQvxXWk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in CSV file. Have to change encoding because it would throw errors if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trey Benson</td>\n",
       "      <td>I think Trey fits us from a schematic standpoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Trey Benson</td>\n",
       "      <td>And then one thing that stands out about Trey ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MarShawn Lloyd</td>\n",
       "      <td>No, I would like to get him out there as much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bucky Irving</td>\n",
       "      <td>The nice thing I like about Bucky is he gets t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bucky Irving</td>\n",
       "      <td>He has taken every detail that we’ve coached t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Name                                              Tweet\n",
       "0   1     Trey Benson  I think Trey fits us from a schematic standpoi...\n",
       "1   2     Trey Benson  And then one thing that stands out about Trey ...\n",
       "2   3  MarShawn Lloyd  No, I would like to get him out there as much ...\n",
       "3   4    Bucky Irving  The nice thing I like about Bucky is he gets t...\n",
       "4   5    Bucky Irving  He has taken every detail that we’ve coached t..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('DataTweets.csv', encoding='cp1252')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think Trey fits us from a schematic standpoint, in that he’s instinctive, he’s tough, he’s physical, he’s got good contact balance, he’s able to run through and gain tough yards.\n"
     ]
    }
   ],
   "source": [
    "example = df['Tweet'][0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the nltk tokenize function which splits the text into tokens. Not related to the roberta model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'think',\n",
       " 'Trey',\n",
       " 'fits',\n",
       " 'us',\n",
       " 'from',\n",
       " 'a',\n",
       " 'schematic',\n",
       " 'standpoint',\n",
       " ',']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(example)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling in a very specific model that has been pretrained on sentiment. Hugging face gives us this. The model was already trained on twitter comments, so we don't have to retrain the model at all. Pre-trained weights are already applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12505\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the roberta model on our example. First thing is encoding on text using the tokenizer allowing the model to understand it (0s and 1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.0035831851, 'roberta_neu': 0.21310855, 'roberta_pos': 0.78330815}\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer(example, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to run the model on for each piece of text we give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "    'roberta_neg': scores[0],\n",
    "    'roberta_neu': scores[1],\n",
    "    'roberta_pos': scores[2]\n",
    "}\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing our results for the entire dataset into a dictionary which we will then convert to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ebf31f087443468fc8bb048a312413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try: \n",
    "        tweet = row['Tweet']\n",
    "        tweetId = row['Id']\n",
    "        roberta_result = polarity_scores_roberta(tweet)\n",
    "        res[tweetId] = roberta_result\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the dictionary to a dataframe and then merging the original dataframe (df) with our new dataframe to get a side by side of the scores with the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(res).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
    "results_df = results_df.merge(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>Name</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.213109</td>\n",
       "      <td>0.783308</td>\n",
       "      <td>Trey Benson</td>\n",
       "      <td>I think Trey fits us from a schematic standpoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.114290</td>\n",
       "      <td>0.881694</td>\n",
       "      <td>Trey Benson</td>\n",
       "      <td>And then one thing that stands out about Trey ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.160118</td>\n",
       "      <td>0.833143</td>\n",
       "      <td>MarShawn Lloyd</td>\n",
       "      <td>No, I would like to get him out there as much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010072</td>\n",
       "      <td>0.089185</td>\n",
       "      <td>0.900744</td>\n",
       "      <td>Bucky Irving</td>\n",
       "      <td>The nice thing I like about Bucky is he gets t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.022405</td>\n",
       "      <td>0.748693</td>\n",
       "      <td>0.228902</td>\n",
       "      <td>Bucky Irving</td>\n",
       "      <td>He has taken every detail that we’ve coached t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.840049</td>\n",
       "      <td>0.114377</td>\n",
       "      <td>Breece Hall</td>\n",
       "      <td>Breece is the unquestioned bellcow, but even t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.098714</td>\n",
       "      <td>0.897054</td>\n",
       "      <td>Malachi Corley</td>\n",
       "      <td>He is raw, from a route-running ability standp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.110729</td>\n",
       "      <td>0.745430</td>\n",
       "      <td>0.143841</td>\n",
       "      <td>Drake Maye</td>\n",
       "      <td>Ultimately, he still has to win that job and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.239015</td>\n",
       "      <td>0.594932</td>\n",
       "      <td>0.166052</td>\n",
       "      <td>Drake Maye</td>\n",
       "      <td>I don’t think many rookies are ready to just j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.123267</td>\n",
       "      <td>0.871451</td>\n",
       "      <td>Derrick Henry</td>\n",
       "      <td>He ran very well in Tennesee. I think what it’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.409611</td>\n",
       "      <td>0.577998</td>\n",
       "      <td>Ben Sinnott</td>\n",
       "      <td>He can do a lot of different things… He has th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>0.543904</td>\n",
       "      <td>0.440141</td>\n",
       "      <td>Nick Chubb</td>\n",
       "      <td>With Nick [Chubb], obviously, we’ll continue t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>0.346437</td>\n",
       "      <td>0.633854</td>\n",
       "      <td>Christian Watson</td>\n",
       "      <td>Christian Watson is “in a great place now” wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.011445</td>\n",
       "      <td>0.311536</td>\n",
       "      <td>0.677020</td>\n",
       "      <td>Devontez Walker</td>\n",
       "      <td>\"[Smith] made big plays when they counted. You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.006339</td>\n",
       "      <td>0.162784</td>\n",
       "      <td>0.830877</td>\n",
       "      <td>Joe Burrow</td>\n",
       "      <td>Joe Burrow says “there’s still good days and b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.470272</td>\n",
       "      <td>0.515263</td>\n",
       "      <td>Treylon Burks</td>\n",
       "      <td>\"[Boyd signing] means you don't have to rely o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.025439</td>\n",
       "      <td>0.973027</td>\n",
       "      <td>MarShawn Lloyd</td>\n",
       "      <td>\"I like his speed. I like his speed a lot. He ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.069088</td>\n",
       "      <td>0.928203</td>\n",
       "      <td>Xavier Worthy</td>\n",
       "      <td>\"Xavier is quick, Xavier is quick. No surprise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.119752</td>\n",
       "      <td>0.872162</td>\n",
       "      <td>Xavier Worthy</td>\n",
       "      <td>“I thought he did a nice job picking things up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.317371</td>\n",
       "      <td>0.671674</td>\n",
       "      <td>Jalen McMillan</td>\n",
       "      <td>Bucs WR coach Bryan McClendon says that he lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>0.839317</td>\n",
       "      <td>Anthony Richardson</td>\n",
       "      <td>“This is progressing really well. I'm told Ric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  roberta_neg  roberta_neu  roberta_pos                Name  \\\n",
       "0    1     0.003583     0.213109     0.783308         Trey Benson   \n",
       "1    2     0.004016     0.114290     0.881694         Trey Benson   \n",
       "2    3     0.006738     0.160118     0.833143      MarShawn Lloyd   \n",
       "3    4     0.010072     0.089185     0.900744        Bucky Irving   \n",
       "4    5     0.022405     0.748693     0.228902        Bucky Irving   \n",
       "5    6     0.045574     0.840049     0.114377         Breece Hall   \n",
       "6    7     0.004232     0.098714     0.897054      Malachi Corley   \n",
       "7    8     0.110729     0.745430     0.143841          Drake Maye   \n",
       "8    9     0.239015     0.594932     0.166052          Drake Maye   \n",
       "9   10     0.005282     0.123267     0.871451       Derrick Henry   \n",
       "10  11     0.012392     0.409611     0.577998         Ben Sinnott   \n",
       "11  12     0.015956     0.543904     0.440141          Nick Chubb   \n",
       "12  13     0.019709     0.346437     0.633854    Christian Watson   \n",
       "13  14     0.011445     0.311536     0.677020     Devontez Walker   \n",
       "14  15     0.006339     0.162784     0.830877          Joe Burrow   \n",
       "15  16     0.014465     0.470272     0.515263       Treylon Burks   \n",
       "16  17     0.001534     0.025439     0.973027      MarShawn Lloyd   \n",
       "17  18     0.002709     0.069088     0.928203       Xavier Worthy   \n",
       "18  19     0.008086     0.119752     0.872162       Xavier Worthy   \n",
       "19  20     0.010955     0.317371     0.671674      Jalen McMillan   \n",
       "20  21     0.004275     0.156407     0.839317  Anthony Richardson   \n",
       "\n",
       "                                                Tweet  \n",
       "0   I think Trey fits us from a schematic standpoi...  \n",
       "1   And then one thing that stands out about Trey ...  \n",
       "2   No, I would like to get him out there as much ...  \n",
       "3   The nice thing I like about Bucky is he gets t...  \n",
       "4   He has taken every detail that we’ve coached t...  \n",
       "5   Breece is the unquestioned bellcow, but even t...  \n",
       "6   He is raw, from a route-running ability standp...  \n",
       "7   Ultimately, he still has to win that job and w...  \n",
       "8   I don’t think many rookies are ready to just j...  \n",
       "9   He ran very well in Tennesee. I think what it’...  \n",
       "10  He can do a lot of different things… He has th...  \n",
       "11  With Nick [Chubb], obviously, we’ll continue t...  \n",
       "12  Christian Watson is “in a great place now” wit...  \n",
       "13  \"[Smith] made big plays when they counted. You...  \n",
       "14  Joe Burrow says “there’s still good days and b...  \n",
       "15  \"[Boyd signing] means you don't have to rely o...  \n",
       "16  \"I like his speed. I like his speed a lot. He ...  \n",
       "17  \"Xavier is quick, Xavier is quick. No surprise...  \n",
       "18  “I thought he did a nice job picking things up...  \n",
       "19  Bucs WR coach Bryan McClendon says that he lik...  \n",
       "20  “This is progressing really well. I'm told Ric...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average the scores for each of the three columns, grouped by the player names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Negative   Neutral  Positive\n",
      "0   Anthony Richardson  0.004275  0.156407  0.839317\n",
      "1          Ben Sinnott  0.012392  0.409611  0.577998\n",
      "2          Breece Hall  0.045574  0.840049  0.114377\n",
      "3         Bucky Irving  0.016238  0.418939  0.564823\n",
      "4     Christian Watson  0.019709  0.346437  0.633854\n",
      "5        Derrick Henry  0.005282  0.123267  0.871451\n",
      "6      Devontez Walker  0.011445  0.311536  0.677020\n",
      "7           Drake Maye  0.174872  0.670181  0.154947\n",
      "8       Jalen McMillan  0.010955  0.317371  0.671674\n",
      "9           Joe Burrow  0.006339  0.162784  0.830877\n",
      "10      Malachi Corley  0.004232  0.098714  0.897054\n",
      "11      MarShawn Lloyd  0.004136  0.092779  0.903085\n",
      "12          Nick Chubb  0.015956  0.543904  0.440141\n",
      "13         Trey Benson  0.003800  0.163699  0.832501\n",
      "14       Treylon Burks  0.014465  0.470272  0.515263\n",
      "15       Xavier Worthy  0.005397  0.094420  0.900182\n"
     ]
    }
   ],
   "source": [
    "grouped_df = results_df[['Name', 'roberta_neg', 'roberta_neu', 'roberta_pos']].groupby('Name')\n",
    "\n",
    "# Calculate the mean of each group\n",
    "averages_df = grouped_df.mean().reset_index()\n",
    "averages_df = averages_df.rename(columns={\n",
    "    'roberta_neg': 'Negative',\n",
    "    'roberta_neu': 'Neutral',\n",
    "    'roberta_pos': 'Positive'\n",
    "})\n",
    "# Print the resulting dataframe\n",
    "print(averages_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing these scores into the excel sheet with predefined player names. There is an error where I have to delete the file everytime I want to write to it, but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel sheet\n",
    "excel_file = 'DataTweets.xlsx'\n",
    "excel_df = pd.read_excel(excel_file, sheet_name='Scores')\n",
    "\n",
    "# Merge the Excel dataframe with the averages dataframe based on the 'Name' column\n",
    "merged_df = pd.merge(excel_df, averages_df, on='Name', how='left')\n",
    "\n",
    "\n",
    "# Identify columns to replace\n",
    "replace_columns = [col for col in existing_data.columns if col in new_data.columns]\n",
    "# Write the merged dataframe back to a specific sheet within the Excel file\n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a') as writer:\n",
    "    merged_df.to_excel(writer, sheet_name='Scores', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick and easy way to run sentiment predictions via the pretrained pipelines that hugging face offers. There are more models that you can specify but this is a quick way of doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\12505\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sent_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9919127225875854}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_pipeline(df['Tweet'][15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"[Boyd signing] means you don\\'t have to rely on Burks to produce, which takes the pressure off of him and allows him to just go make plays when he gets opportunities (yes as that 4th receiver).'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
